{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "# Reduce logging output.\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "## Data\n",
    "We will try to solve the [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) task [(Mass et al., 2011)](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf). The dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. The task is to label the reviews as **negative** or **positive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_df:25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely the very first film that scared me ...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A lot of people don't think Branagh's Hamlet f...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr Tarr's Torture Dungeon is about a journalis...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is cold, bare truth. Often we think...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I caught this movie on FX last night, and as I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  polarity\n",
       "0  Absolutely the very first film that scared me ...         8         1\n",
       "1  A lot of people don't think Branagh's Hamlet f...        10         1\n",
       "2  Dr Tarr's Torture Dungeon is about a journalis...         4         0\n",
       "3  This movie is cold, bare truth. Often we think...         9         1\n",
       "4  I caught this movie on FX last night, and as I...         1         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "  dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "  \n",
    "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "  \n",
    "  return train_df, test_df\n",
    "\n",
    "train_df, test_df = download_and_load_datasets()\n",
    "print(f'len train_df:{len(train_df)}')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Tensor Data\n",
    "\n",
    "In order to use Tensorflow 2.1.0 we need to use td.data.Dateset. This objects are data containers useful to apply tensorflow pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b'I remember following the case of Andre Chicatillo in the newspapers while I was living in South Africa. They had photos of him sitting in his cage while being prosecuted in court. Not, as it turned out, to protect the court members, but to protect him from the public. This was fascinating, albeit morbid, reading. I later heard that a film had been made by HBO about the case, but it was made for American TV. Bummed! Strangely, CITIZEN X got a limited cinematic release in South Africa. I charged down to the local Ster Kinekor complex and duly bought a ticket (I was alone; my girlfriend at the time was only interested in the likes of STEEL MAGNOLIAS and FRIED GREEN TOMATOES). Wow! What a brilliant film. Why wasn\\'t it released to a wider audience? Had it not been made for TV, it could have got an Oscar nomination or 2. There is no way to spoil the ending; who the killer is is never kept from the audience. Jeffrey DeMunn portrays a truly terrifying psycho. He is calm, downtrodden, considered a failure by his wife and subjected to constant ridicule and humiliation by his superiors at work. By committing these horrendous acts, he gets to feel strong, powerful.<br /><br />Fighting to catch him against all odds is a pathologist, played to excellent turn by Stephen Rea, in one of his strongest performances. He must battle the snail-pace of Russian bureaucracy, the primitive resources he has at his disposal and (above all) the refusal by his superiors to acknowledge that the USSR even has a serial killer. The general in charge (Joss Ackland) says that serial killers are \"a decadent, Western phenomenon\". Only Donald Sutherland is willing to help, but his help must be under the counter. The ever-brilliant Max Von Sydow plays a Russian psychiatrist who breaks protocol and decides to help the investigators in their quest. It is the first time in Russian history that a shrink is used to build a profile of a serial killer still on the loose, and he has everything to lose if his involvement is made public.<br /><br />CITIZEN X is brilliantly acted, well written and the music and editing only add to the tension and theme of the film. Excellent support from a horribly underused Imelda Staunton and a real sense of impending doom make CITIZEN X a film worth seeing. This was too good to be made for TV',\n",
       "       b'As a study of the frailties of human nature in the context of old age, this film is without parallel. It is, quite simply, brilliant. Full marks to everyone - from the scriptwriter to all involved in the finished product. You can only marvel at the perceptions inherent in the characterisation of the two ageing performers.',\n",
       "       b'Watching \"The Fox and the Child\" was an intoxicating experience. The lush visuals, integrity of point of view, and utter beauty of the setting and characters left me in a swoon of pleasure.<br /><br />The plot is uncomplicated. Deceptively simple. Within the container of that simplicity a world unfolds that draws you in and leaves you breathless.<br /><br />I laughed. I wept. I learned.<br /><br />This is a movie you can trust yourself to -- give yourself over to. Dare I say it is an act of love intended for any innocent heart. It reaches to the heart of the viewer--of any age--and reveals the world through new eyes, as if seen from the heart.<br /><br />Adi Da Samraj once said that true Art draws the viewer beyond point of view into ecstatic participation in Reality. I feel I have been privileged to watch--no, to participate in--this film, a work of true Art.',\n",
       "       b'I bought the DVD of Before Sunset and saw it for the first time a week ago. Having saw it twice, I couldn\\'t help but missing Before Sunrise, not because the sequel was not as great, but I felt that these two movies completed each other like no other sequels ever did, every time I finished watching one of them, I feel the need and yearning to see the other. So, I ended up spending the weeks watching both of them repeatedly, I will be quite embarrassed to mention how many times exactly. The most remarkable thing about Before Sunrise is how you feel the development of the feelings of their characters towards each other. It sounds so simple, the growing of the chemistry, I think other romantic films might think that they succeed to track the development, but to me - who doesn\\'t believe in Nora Ephron - Before Sunrise is the first film to really gives the viewers chance to feel it. When I saw it for the first time, about 8 year ago when I was 20, I already liked it. But, I didn\\'t rate it as a \"great film\", it still seemed to me like another thinking persons\\' feel good movie, Linklater was too smart to make it more realistic, it was 10 minutes too long, the characters was too well fabricated, I thought I liked it because it was like a dream and because I enjoyed their conversations, etc. etc.. But now, thanks to Before Sunset, I feel that\\'s more to Before Sunrise than what I felt for it before. I saw the elements more clearly: Jesse, Celine, Vienna, their conversations, everything. How each of them are separated element by itself, and they have a chance to mix, the story is just a frame of time, I am no longer feel manipulated. And the freedom that every scene has, as well as its refusal to be overly efficient, how blind I was that those qualities didn\\'t strike me as exceptional when I first saw it! Now, 8 year have passed, the more movies I\\'ve seen, the more I realize that many movies are just collections of ordered scenes that only exist for the sake of its ending, even movies like Pulp Fiction or Linklaters\\'s own Slackers included. The Jesse and Celine tale avoid that, maybe Before Sunset is a better example in this case, but Before Sunrise is also one of few films that its ending is just a consequence of time, not a destination, every single scene has its own life. I don\\'t know whether Linklater or anyone else had a sequel in mind when they made Before Sunrise, but to me, one of the most amazing things about these sequels are how these two films visually contrast each other. Before Sunrise which I think employs more static angels and brighter color schemes, seems to try to capture the smallest atoms of liveliness surrounding Jesse and Celine, the world is always full of hope whether or not the characters feel it. Meanwhile, I enter the vision of boredom as Jesse stuck talking to the journalists in Before Sunset, and Celine\\'s first smile from behind the shelves are the most heartbreaking smile I\\'ve seen in a beginning of a film, and the many moving shots after that takes me to a place I don\\'t know with a sadness in me, no matter how beautiful Paris is, and no matter how happy I am that they meet again. I\\'m sorry that I go on this long with my limited English, Before Sunrise is already an extraordinary film without me pouring my scattered thoughts, and it gets even better with an equally great sequel following it.',\n",
       "       b'If you are a traveller, if there is a fire burning into your heart, if you\\'d call \"home\" every place on earth, but none of them can give you enough, if you are always looking for the next thing and if you believe the other part of your soul is somewhere out there, see this movie and you\\'ll find out a little, but wonderful, piece of life sitting next to you.',\n",
       "       b\"Just finished watching the movie and wanted to give my own opinion(and justice) to the movie.<br /><br />First of all, to get things straight, this movie is not pretending to be anything other than a solid action comedy movie. It doesn't aim to revolutionize the movie industry and garner critical acclaims nor does it want to be regarded as one. If you really want to enjoy this movie to the fullest, I suggest you discard your critical-mindedness and your longing for a good plot because you won't find any in here. With that established, let us further into the movie.<br /><br />I had low expectations for this movie simply because it didn't have a strong plot(Yes, moviegoers, I underrated this movie as well), but I never expected myself to enjoy this movie that much. I even enjoyed this more than the Stephen Chow flicks(which I find Kung Fu Hustle to be his best effort and would've rated it a 9 as well). Action is tight and epic while comedy chokes on to the right places.<br /><br />SPOILERS alert, I think The action might be unreal, but why would I want to watch a serious basketball movie anyways? There are a lot other sports movies(drama) that already did it well, why create another? SPOILERS end<br /><br />I'm not even sure why you're reading this. Go ahead and watch it. Just remember, no thinking - just watch, enjoy, smile, laugh, and <br /><br />Every once in a while they(the movie industry) creates masterpieces such as Pulp Fiction or The Godfather movies, and sometimes they create movies which are better off in the pile of dump. I'm not saying Kung Fu Dunk deserves the recognition that the previous examples have, then again, if we're talking about Stephen Chow-ish comedy, this one's a top ten.<br /><br />Highly recommended if you love: -no brainer movies with really good action -Kung Fu -Death Trance -Kung Fu and comedy -what the heck, watch this. you'll have a great time.<br /><br />9/10 for you the cast of Kung Fu Dunk. ^_^\",\n",
       "       b'I don\\'t know where to begin. This movie feels a lot like one of those cheap Saturday morning kids shows that they used to make back in the late eighties early nineties. Sort of like Captain Power or the Power Rangers. It\\'s full of bad digital overlays and really cheesy sounding \"secret agencies\" and villains.<br /><br />The acting is so bad that it\\'s not even funny. The direction is terrible and there is little to now continuity. It seems as if someone just threw a bunch of scenes together and forgot that there was supposed to be a plot.<br /><br />Perhaps one of the most ridiculous scenes in the movie comes early on, when several villains plant an explosive device in an agents car. For some reason, even though the device is clearly stated as being \"remote detonated\" the bad guys decide to chase her down on their motorcycles as she drives away. This chase carries on. all the while with the bad guys doing ludicrous and completely pointless bike stunts. Standing up on the bikes, doing wheelies and so on. At one point, a crash happens and one of the attackers is thrown from his bike, we see the bike (clearly cgi) thrown over the agents car but the rider has vanished. Then, a few seconds later the rider and bike return...apparently unscathed by the crash. At this point even though the car has an explosive device planted in it, the attackers choose to shoot the agent while driving past, then blow up her car. Which was also clearly done with cgi. Sound confusing? It is, and so is the rest of the movie.<br /><br />I might point out that when I say cgi, we aren\\'t talking about Lord Of The Rings type cgi here. We\\'re talking the cheap cheesy Power Rangers type cgi, actually I think it would have been done better on Power Rangers.<br /><br />Why Savini and Todd did this movie I will never know, I can only assume they did for money, as a favor to someone or because they were blackmailed into it...probably the last one.',\n",
       "       b\"What a disgrace! I was checking this out hoping it would be an undiscovered James Garner gem and what a stinker it turned out to be! The production quality was fine, but the plot was undeniably lame and I can honestly say that I am only a couple hours older and a lot dumber now. The movie really had no redeeming qualities and if this kind of stuff keeps coming out, it will give Hallmark a bad name. For those of you who insist on knowing what it was about, it's about nothing, and in this case, it's not a good thing. We are subjected to watching one old ornery woman who is one of the dumbest creatures ever to roam the earth, who happens to be married to a real sweetheart who is probably the only person alive that could put up with her. She drags him through one mess after another, gets him into one embarrassing situation after another, and is proud of herself the whole time. Then the movie ends. What a relief that was! Not worth the time it would take to watch it, so do yourself a favor and skip this one, you'll be glad you did if you knew how bad this one really is.\",\n",
       "       b'I have just watched the movie for the first time. I wanted to watch it as I like Drew Barrymore and wanted to see one of her early movies. <br /><br />The movie is about a girl (played by young and beautiful Drew Barrymore), who moves from NYC to LA in order to get over her recently troubled loss. Short after moving to a guy who falls in love with her, it becomes obvious that she has an evil twin=doppelganger, who haunts her.<br /><br />The movie is quite poor and lousy. Both the dialogs and the acting make the film not really worth seeing it. Summing up it is just something for the fans of Drew Barrymore.',\n",
       "       b\"What the movie The 60s really represents (to those of us who growled around in the belly of America in those times) is the turbulence and diversity of the decade. Despite the exaggerated, stereotyped characters, the genuineness of the issues remains clear.<br /><br />Not only were those radical times of change, but also very confusing times. Two basic things changed our world then: the 1964 Civil Rights Act, and the overwhelming influence of the media. Those two new freedoms began social changes that soon became institutionalized.<br /><br />From chaos came sensitivity, from disorder came values. Bear in mind however, that the bulk of Americans were not involved in this... they worked, they played, they watched the news... and slowly they became effected by the efforts and struggles of the minorities... the Civil Rights workers, the Political Activists, the Anti-War efforts, the War on Poverty....<br /><br />The representation of the power of the press and TV in particular, was well reflected, although the conflict between the general public's attitude and those seeking to change things was at best ignored... and at worst, misrepresented.. Middle class Americans weren't all standing around angrily holding baseball bats, or disowning their wayward daughters. They were confused too. Let us not forget how Folk Singers suddenly became Protest Singers, and how The Beatles began an onslaught that killed the Folk-Protest Movement. There are no Beatle songs in the movie, or even any mention of them.<br /><br />I think if you didn't live the decade, you might not have a sense of what the movie is about, the overall picture is a bit dim. At one point I held down a steady job while my sister lived at the Hog Farm Commune and went to Woodstock. At another point I was in Haight Asbury and in the Detroit Riots while she worked and played the housewife in Maine and Connecticut. Roles were constantly changing.<br /><br />The movie depicts three siblings of a middle class family. They represent the hippie child, the political activist, and the active military personnel. Dad represents the typical attitudes, and mom represents the voice of reason, tolerance, and sometimes compromise... for the sake of peace.<br /><br />The Black family comprises a minister and his son... disproportionately, I think. I assume the producers knew all the variables and had to settle on limitations, or else the film would have become a long, boring, documentary. Dad's message was that anger produces bitterness, and bitterness produces chaos. It was clearly a message directed to today's youth.<br /><br />We are looking at a unique solution to social problems, and also how issues divide us... The 60s were unusual in that way, and only the Roaring 20s compare. In other words, this movie has a moral after all. In the end, it is our Collective Individualism that survives. Put that in your oxymoron list.<br /><br />Everyone was a God, a Guru, or a free-spirited genius in the 60s. It was a time of magic and madness. No one will ever nail the 60s down right... it was too diverse (this movie is close). At least we can say we are not ashamed of it, that we learned and grew from it, and that for once, a generation shaped and changed America... for the better.\"],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_qty = int(len(train_df)*0.1)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((list(train_df['sentence'].values)[validation_qty:], \n",
    "                                              list(train_df['polarity'].values)[validation_qty:])\n",
    "                                            )\n",
    "\n",
    "validate_ds = tf.data.Dataset.from_tensor_slices((list(train_df['sentence'].values)[:validation_qty], \n",
    "                                              list(train_df['polarity'].values)[:validation_qty])\n",
    "                                            )\n",
    "\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((list(test_df['sentence'].values), \n",
    "                                              list(test_df['polarity'].values))\n",
    "                                            )\n",
    "train_examples_batch, train_labels_batch = next(iter(train_ds.batch(10)))\n",
    "train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "\n",
    "TF-Hub provides a [feature column](https://www.tensorflow.org/hub/api_docs/python/hub/text_embedding_column.md) that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the [nnlm-en-dim128 module](https://tfhub.dev/google/nnlm-en-dim128/1). For the purpose of this tutorial, the most important facts are:\n",
    "\n",
    "* The module takes **a batch of sentences in a 1-D tensor of strings** as input.\n",
    "* The module is responsible for **preprocessing of sentences** (e.g. removal of punctuation and splitting on spaces).\n",
    "* The module works with any input (e.g. **nnlm-en-dim128** hashes words not present in vocabulary into ~20.000 buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string)\n",
    "#hub_layer(train_examples_batch[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Classifier\n",
    "\n",
    "For classification we can use a DNN Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <tensorflow.python.saved_model.function_deserialization.RestoredFunction object at 0x7f06f7625f60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Could not find matching function to call loaded from the SavedModel. Got:\n",
      "  Positional arguments (3 total):\n",
      "    * Tensor(\"inputs:0\", shape=(None,), dtype=string)\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments: {}\n",
      "\n",
      "Expected these arguments to match one of the following 4 option(s):\n",
      "\n",
      "Option 1:\n",
      "  Positional arguments (3 total):\n",
      "    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments: {}\n",
      "\n",
      "Option 2:\n",
      "  Positional arguments (3 total):\n",
      "    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n",
      "    * True\n",
      "    * None\n",
      "  Keyword arguments: {}\n",
      "\n",
      "Option 3:\n",
      "  Positional arguments (3 total):\n",
      "    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments: {}\n",
      "\n",
      "Option 4:\n",
      "  Positional arguments (3 total):\n",
      "    * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n",
      "    * False\n",
      "    * None\n",
      "  Keyword arguments: {}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py:173 call  *\n        result = smart_cond.smart_cond(training,\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py:56 smart_cond\n        return false_fn()\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py:438 _call_attribute\n        return instance.__call__(*args, **kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:568 __call__\n        result = self._call(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:606 _call\n        results = self._stateful_fn(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2362 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2703 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2593 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:978 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:439 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py:262 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * Tensor(\"inputs:0\", shape=(None,), dtype=string)\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * False\n        * None\n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aed20c05f53b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    183\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    772\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_hub/keras_layer.py:173 call  *\n        result = smart_cond.smart_cond(training,\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py:56 smart_cond\n        return false_fn()\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py:438 _call_attribute\n        return instance.__call__(*args, **kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:568 __call__\n        result = self._call(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:606 _call\n        results = self._stateful_fn(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2362 __call__\n        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2703 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py:2593 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:978 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:439 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/chanchus/developments/movies_classifier/venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py:262 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * Tensor(\"inputs:0\", shape=(None,), dtype=string)\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * False\n        * None\n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train the estimator for a reasonable amount of steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Run predictions for both training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds.shuffle(10000).batch(512),\n",
    "                    epochs=5,\n",
    "                    validation_data=validate_ds.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 2s - loss: 0.5662 - accuracy: 0.8698\n",
      "loss: 0.566\n",
      "accuracy: 0.870\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_ds.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABELS = [\n",
    "    \"negative\", \"positive\"\n",
    "]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "cm = tf.math.confusion_matrix(test_df[\"polarity\"], \n",
    "                              model.predict(test_ds.batch(512)) > 0.5)\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm = tf.cast(cm, dtype=tf.float32)\n",
    "cm = cm / tf.math.reduce_sum(cm, axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98417956]], dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(['It was great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
