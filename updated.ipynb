{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "# Reduce logging output.\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "## Data\n",
    "We will try to solve the [Large Movie Review Dataset v1.0](http://ai.stanford.edu/~amaas/data/sentiment/) task [(Mass et al., 2011)](http://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf). The dataset consists of IMDB movie reviews labeled by positivity from 1 to 10. The task is to label the reviews as **negative** or **positive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the 28th of December, 1895, in the Grand Ca...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A really sweet movie that has some similaritie...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wanted to like this film, yes its a SAW, bla...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After we counted the use of the f word, oh, ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had never heard of this Adam Sandler movie u...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment  polarity\n",
       "0  On the 28th of December, 1895, in the Grand Ca...         8         1\n",
       "1  A really sweet movie that has some similaritie...         7         1\n",
       "2  I wanted to like this film, yes its a SAW, bla...         2         0\n",
       "3  After we counted the use of the f word, oh, ab...         1         0\n",
       "4  I had never heard of this Adam Sandler movie u...         1         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all files from a directory in a DataFrame.\n",
    "def load_directory_data(directory):\n",
    "  data = {}\n",
    "  data[\"sentence\"] = []\n",
    "  data[\"sentiment\"] = []\n",
    "  for file_path in os.listdir(directory):\n",
    "    with tf.io.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
    "      data[\"sentence\"].append(f.read())\n",
    "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
    "  return pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Merge positive and negative examples, add a polarity column and shuffle.\n",
    "def load_dataset(directory):\n",
    "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
    "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
    "  pos_df[\"polarity\"] = 1\n",
    "  neg_df[\"polarity\"] = 0\n",
    "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Download and process the dataset files.\n",
    "def download_and_load_datasets(force_download=False):\n",
    "  dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb.tar.gz\", \n",
    "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", \n",
    "      extract=True)\n",
    "  \n",
    "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                       \"aclImdb\", \"train\"))\n",
    "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
    "                                      \"aclImdb\", \"test\"))\n",
    "  \n",
    "  return train_df, test_df\n",
    "\n",
    "train_df, test_df = download_and_load_datasets()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### Input functions\n",
    "\n",
    "[Estimator framework](https://www.tensorflow.org/get_started/premade_estimators#overview_of_programming_with_estimators) provides [input functions](https://www.tensorflow.org/api_docs/python/tf/estimator/inputs/pandas_input_fn) that wrap Pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=string, numpy=\n",
       "array([b\"On the 28th of December, 1895, in the Grand Caf\\xc3\\xa9 in Paris, film history was writing itself while Louis Lumi\\xc3\\xa8re showed his short films, all single shots, to a paying audience. 'La Sortie des Usines Lumi\\xc3\\xa8re' was the first film to be played and I wish I was there, not only to see the film, but also the reactions of the audience.<br /><br />We start with closed doors of the Lumi\\xc3\\xa8re factory. Apparently, since the image seems a photograph, people thought they were just going to see a slide show, not something they were hoping for. But then the doors open and people are streaming out, heading home. First a lot of women, then some men, and one man on a bike with a big dog. When they are all out the doors close again.<br /><br />Whether this is the first film or not (some say 'L'Arriv\\xc3\\xa9e d'un Train \\xc3\\xa0 la Ciotat' was the first film Lumi\\xc3\\xa8re recorded), it is an impressive piece of early cinema. Being bored by this is close to impossible for multiple reasons. One simple reason: it is only fifty seconds long. But also for people who normally only like the special effect films there must be something interesting here; you don't get to see historical things like this every day.\",\n",
       "       b'A really sweet movie that has some similarities to the 2001-hit \"My Sassy Girl\" but is able to enchant most of the time. The biggest applause should go to the two leads. Ha-Neul Kim is both sweet and quirky, Sang-woo Kwon is both attractive and rebellious. The chemistry between the two is very good.<br /><br />Director Kyeong-hyeong Kim uses some CG-inserts to pepper up the visuals and also offers impressive fight scenes in which Sang-woo Kwon can shine. I liked him a lot better here than in the highly overrated \"Volcano High\". And that boy has a future - those looks, those fight techniques, and a romantic lead. Not bad.<br /><br />Well, I can make it short: Nice film. My rating: 7/10',\n",
       "       b'I wanted to like this film, yes its a SAW, blah blah blah ripoff but I like those films. If done well this had all the ingredients of being a good, not brilliant, but good film....unfortunately those ingredients had gone off! The acting was terrible, and this was first seen when the captives are introduced with their captor one by one (hoods taken off), the remarks and one liners are just terrible, yes I know, bad writing....but this is more than that, it was bad writing coupled with bad acting. Two of the captives had been in a relationship with each other and did not even acknowledge this until a lot further into the film.....<br /><br />Sorry, Im even wondering why I am bothering to review this movie at all.<br /><br />I will end with PLOT HOLES, PLOT HOLES & MORE PLOT HOLES! DISAPPOINTING!',\n",
       "       b\"After we counted the use of the f word, oh, about 22 times in the first 10 minutes or so of the film, listened to some really bad actors going on about a woman and a horse, and pretty much acting like 12 year old boys being naughty together, well, we turned it off. Relying on gratuitous profanity and potty humor is a sure sign of a loser Hollywood movie, the product of unimaginative and no-talent writers. <br /><br />We did give it a second chance, thinking surely it would get better. No dice. Later, my boyfriend skipped through the rest of the movie in case it improved, still no dice.<br /><br />The main character did have a cool bike.<br /><br />I wouldn't recommend this to anyone except maybe really immature adolescents, or frat boys.\",\n",
       "       b'I had never heard of this Adam Sandler movie until I saw it on the wall at Blockbuster. Being an Adam Sandler fan at the time, I rented it. HONESTLY I could only watch about 30 mins. of it. It was TERRIBLE. Do whatever it takes to keep this out of the hands of the public. I honestly hope this movie goes OOP soon, and I hope it STAYS THAT WAY!',\n",
       "       b\"This production never really got off the ground for me. The plot is so cut up as to be disjointed and the production is so short that unless you've read the novel or seen a better adaptation (like the 1995 one with Amanda Root) you're going to be a bit lost since there's no time for character development.<br /><br />I liked Sally Hawkins as Anne, but the rest of the cast fell rather short of what they should have been. Mrs. Croft was far too old, as was Anne's elder sister Elizabeth. Mary uttered everything in such throbbing accents that the general peevishness and selfishness of her character was lost. Much better was Sophie Thompson's Mary, whose selfishness and sense of ill-usage is so well established that by the time Wentworth suggests Anne stay with the injured Louisa and Mary objects that she, as Louisa's sister in law, should stay instead, you can't imagine anyone less suited to do so. In this version, she might as well stay as she is insufficiently differentiated from anyone else in the production.<br /><br />Rupert Penry-Jones is nice to look at, but he made a much better St. John Rivers (1995 Jane Eyre), probably because that character required less implied depth of feeling. I agree with the comments made earlier about the gig scene: seemed more like he was trying to get rid of Anne than do her a favor. Likewise the accident scene: it happens so fast and with so little context, you wonder what all the fuss is about. And moving the speech that Wentworth overhears in the novel to the beginning of this production is a critical misstep that only contributes to the disjointed nature of the script. <br /><br />My other problem with this version was the lighting. Sometimes everything looked like a scene from the CSI morgue -- very very blue. Other times the lighting was so bad it was hard to make out the scene very well, like when Anne visits her old school friend, Mrs. Smith (who, by the way, is supposed to be more or less paralyzed. Having her run up to Anne on the street to tell her of Mr. Elliot's awful character was such a violation that for a minute I couldn't think who she was -- I thought she was one of the Musgrove girls. And she might as well have been. All the girls were pretty much interchangeable). And the running scene at the end...in an era where propriety was at a premium, it's hard to imagine gentle Anne tearing all over Bath like some demented hoyden. How silly can you get? It's too bad. Sally Hawkins had all the makings of a good Anne Elliot, but she was completely hamstrung by a poorly organized script and an over-truncated production.\",\n",
       "       b\"In this 'sequel' Bruce is still called Billy Lo (get it? Bruce= Billy, Lo= Lee. No?) But apart from that, that's all it has in common with the other movie. Billy doesn't seem to be an actor anymore. He seems to be in another country. He's more like a spy. He's the only cast member to return and sadly, they kill him off to make way for a new character, his brother, Bobby. Sadly, when Bruce dies, the movie pretty much dies with him. This was extremely poorly made. It seemed like they were writing the script as they were filming. The footage works for a while (it's not too obvious at first) but soon Bruce is always shown in the dark all the time (he kicks out a light at one stage for no other apparent reason to hide the fact that it's not Bruce playing the part). Sadly when he dies the movie changes. I can't help but wonder if they were filming as they were writing and may well have planned to keep Bruce alive, but later decided to kill him off because it would not have been plausible as Bobby does not appear until Billy is dead. It's hard to change the lead character halfway in the movie and Bruce is a hard act to follow so it's hard to now accept Bobby as the star. Bruce is never seen again in this movie. I think they should have made this sequel without Bruce he has a lame role in this movie. People hoping to see a new Bruce Lee movie will be disappointed to see that although he's given the top billing, he only has a featuring role. Even the worst movies have at least one memorable bit. If there was one bit about this movie people seem to talk about, it's the scene where Billy fights in a plant nursery. Ironically it doesn't even use Bruce Lee footage. Mind you, they did it more convincingly in No Retreat No Surrender. Not one of the other actors here ever made anything else memorable. Bruce's girlfriend (Colleen Camp) is never mentioned. My advice is to turn it off as soon as Bruce is finished writing his letter to his brother. Nothing else in the movie is worth watching. I found it really sad to see Bruce die. I don't see how a small budgeted movie like this could get enough money to use footage from Enter The Dragon. This was a cheap way of trying to cash in on Bruce's name. Oddly this and the original are credited in Bruce's filmography. Thankfully so far, no one has tried anything like this again. 1981 was the year of Bruce's last movie appearance. It was a sad way to end it, but thankfully this is proof that Bruce's movie career should be left alone.\",\n",
       "       b'A propaganda film for the Palestinian \"cause\". If you were expecting an unbiased documentary on the Israeli-Palestinian conflict, you will need to look elsewhere. If you are an anti-Semite (or merely an anti-Zionist---nothing wrong with advocating the destruction of a country, right?) or uncritically in support of Palestinian goals (e.g., mass murder, the destruction of Israel), this is the documentary for you. Should make for an entertaining evening on college campuses around the UK and US. However, any informed and intellectually honest person would be outraged at the sheer number of lies presented in this video. I just hope those who truly are unaware of the situation aren\\'t corrupted by this anti-Semitic filth.',\n",
       "       b'This was director von Stroheim\\'s third effort - it is quite crude and shows none of the exceptional flair for the camera and editing mastery he would display a few years later with his masterworks, GREED and THE WEDDING MARCH. Essentially we have a trio of grifters, masquerading as a Russian count and two Russian princesses who have rented a villa in Monte Carlo. Their aim is to use counterfeit money at the gambling tables and win a fortune. Part of that plan is for the Count (von Stroheim) to insinuate himself between a visiting American ambassador and his \"foolish\" wife, wooing her and hoping to gain some money by playing on her weaknesses. He makes the mistake of also taking the life savings of the maid, whom he has promised to marry. When she sees them together, she sets fire to the room, (von Stroheim and his prey are on the room\\'s balcony). Here von Stroheim first establishes his persona as \"the man you love to hate.\" He is thoroughly bad and his character flaws eventually bring him to a very bad and deserved end. The film is crude in its cinematography and editing and not worth seeing unless you are fascinated by the director. There is a cute bit- when he first attempts to meet the Ambassador\\'s wife, she is reading a book - we see the title - FOOLISH WIVES by Erich von Stroheim. This was originally envisioned as a 210 minute film, cut down to 140 minutes by the studio and finally released at 70 minutes. The restoration on Kino Video restores surviving footage (damaged in some way in most scenes) from the alternate earlier version to give us a 107 minute print.',\n",
       "       b\"I was so glad I came across this short film. I'm always so disappointed that short films are hard to come across, so when I saw this and saw that it was nominated for the Live Action Short Film at the Academy Awards, I was so pleased that I actually had a film that I was rooting for.<br /><br />The plot is pretty simple, the director, writer, and star Nacho Vigalondo tried coming up with a reason people would suddenly break out into a song and dance number like they do in movie musicals. The result is extremely entertaining and the song is actually really catchy.<br /><br />It's a well made short film, well edited and the actors all do a great job. And the last shot of the film is perfect.<br /><br />I highly recommend this film.\"],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((list(train_df['sentence'].values), \n",
    "                                              list(train_df['polarity'].values))\n",
    "                                            )\n",
    "train_examples_batch, train_labels_batch = next(iter(dataset.batch(10)))\n",
    "train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature columns\n",
    "\n",
    "TF-Hub provides a [feature column](https://www.tensorflow.org/hub/api_docs/python/hub/text_embedding_column.md) that applies a module on the given text feature and passes further the outputs of the module. In this tutorial we will be using the [nnlm-en-dim128 module](https://tfhub.dev/google/nnlm-en-dim128/1). For the purpose of this tutorial, the most important facts are:\n",
    "\n",
    "* The module takes **a batch of sentences in a 1-D tensor of strings** as input.\n",
    "* The module is responsible for **preprocessing of sentences** (e.g. removal of punctuation and splitting on spaces).\n",
    "* The module works with any input (e.g. **nnlm-en-dim128** hashes words not present in vocabulary into ~20.000 buckets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 1.7503022 , -3.691709  ,  3.4338055 , -0.3228845 , -5.3861475 ,\n",
       "        -3.3654926 , -3.3583605 , -0.6712539 ,  2.3434281 , -0.20047742,\n",
       "        -3.8665614 ,  2.3881001 , -2.1936314 , -0.17780904, -5.132758  ,\n",
       "         3.0560794 ,  2.9670174 , -2.6617274 , -4.2043767 , -0.23875079],\n",
       "       [ 2.1032414 , -2.3249724 ,  2.3480783 , -1.397995  , -3.4095972 ,\n",
       "        -0.92359406, -1.9300486 ,  0.20443074,  2.04748   , -1.5963868 ,\n",
       "        -1.5896814 ,  1.3238504 , -0.4017688 ,  0.17756465, -3.9853427 ,\n",
       "         0.45209408,  2.6965835 , -0.82818305, -2.8581932 , -1.5970742 ],\n",
       "       [ 1.5073627 , -3.6261086 ,  3.1094828 ,  0.07493318, -4.25405   ,\n",
       "        -3.4359334 , -2.263075  ,  0.3283306 ,  4.0120006 , -0.6195089 ,\n",
       "        -1.5973355 ,  0.5930475 , -0.9117889 ,  0.7780605 , -4.8407664 ,\n",
       "         2.2263017 ,  4.2426443 , -2.1924198 , -2.8274171 , -1.1459619 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "For classification we can use a [DNN Classifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) (note further remarks about different modelling of the label function at the end of the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Train the estimator for a reasonable amount of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 49 steps\n",
      "Epoch 1/20\n",
      "49/49 [==============================] - 3s 53ms/step - loss: 0.6948 - accuracy: 0.6079\n",
      "Epoch 2/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.5687 - accuracy: 0.6820\n",
      "Epoch 3/20\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.5074 - accuracy: 0.7333\n",
      "Epoch 4/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4566 - accuracy: 0.7732\n",
      "Epoch 5/20\n",
      "49/49 [==============================] - 2s 41ms/step - loss: 0.4071 - accuracy: 0.8094\n",
      "Epoch 6/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.3619 - accuracy: 0.8363\n",
      "Epoch 7/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.3246 - accuracy: 0.8572\n",
      "Epoch 8/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2929 - accuracy: 0.8729\n",
      "Epoch 9/20\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.2662 - accuracy: 0.8878\n",
      "Epoch 10/20\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2455 - accuracy: 0.8978\n",
      "Epoch 11/20\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.2258 - accuracy: 0.9099\n",
      "Epoch 12/20\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2092 - accuracy: 0.9166\n",
      "Epoch 13/20\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.1950 - accuracy: 0.9238\n",
      "Epoch 14/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1827 - accuracy: 0.9294\n",
      "Epoch 15/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1699 - accuracy: 0.9372\n",
      "Epoch 16/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1607 - accuracy: 0.9402\n",
      "Epoch 17/20\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1516 - accuracy: 0.9432\n",
      "Epoch 18/20\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1406 - accuracy: 0.9484\n",
      "Epoch 19/20\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 0.1331 - accuracy: 0.9518\n",
      "Epoch 20/20\n",
      "49/49 [==============================] - 2s 40ms/step - loss: 0.1251 - accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.shuffle(10000).batch(512),\n",
    "                    epochs=20,\n",
    "                    #validation_data=validation_data.batch(512),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Run predictions for both training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc5bb0908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc5bb0908>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bc88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bc88>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bc88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bbe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bbe0>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bbe0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bda0>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc410bda0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc4b18908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc4b18908>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe2b0>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe2b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe128>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fe128>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fec88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fec88>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc56fec88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "Training set accuracy: 0.8233199715614319\n",
      "Test set accuracy: 0.8000400066375732\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc56fe828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _DNNModel.call of <tensorflow_estimator.python.estimator.canned.dnn._DNNModel object at 0x7f6fc56fe828>>: AttributeError: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6f28>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6f28>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6e80>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48e6e80>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48f72b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48f72b0>>: ValueError: Unable to locate the source code of <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f6fc48f72b0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_predictions(estimator, input_fn):\n",
    "  return [x[\"class_ids\"][0] for x in estimator.predict(input_fn=input_fn)]\n",
    "\n",
    "LABELS = [\n",
    "    \"negative\", \"positive\"\n",
    "]\n",
    "\n",
    "# Create a confusion matrix on training data.\n",
    "cm = tf.math.confusion_matrix(train_df[\"polarity\"], \n",
    "                              get_predictions(estimator, predict_train_input_fn))\n",
    "\n",
    "# Normalize the confusion matrix so that each row sums to 1.\n",
    "cm = tf.cast(cm, dtype=tf.float32)\n",
    "cm = cm / tf.math.reduce_sum(cm, axis=1)[:, np.newaxis]\n",
    "\n",
    "a = tf.Session().run(cm)\n",
    "\n",
    "sns.heatmap(a, annot=True, xticklabels=LABELS, yticklabels=LABELS);\n",
    "plt.xlabel(\"Predicted\");\n",
    "plt.ylabel(\"True\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
